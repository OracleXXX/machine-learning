{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print('loading data ...')\n",
    "\n",
    "def load_data(filename):\n",
    "\twith open(os.path.join(filename)) as train_f:\n",
    "\t    train_data = json.loads(train_f.read())\n",
    "\n",
    "\tX_train = [x['ingredients'] for x in train_data]\n",
    "\tX_train = [dict(zip(x,np.ones(len(x)))) for x in X_train]\n",
    "\tids = [str(x['id']) for x in train_data]\n",
    "\n",
    "\treturn X_train, ids\n",
    "\n",
    "\n",
    "X_train, _ = load_data('train.json')\n",
    "X_test, test_ids = load_data('test.json')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "X_test = vec.transform(X_test).astype(np.float32)\n",
    "\n",
    "feature_names = np.array(vec.feature_names_)\n",
    "\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "y_train = [y['cuisine'] for y in train_data]\n",
    "y_train = lbl.fit_transform(y_train).astype(np.int32)\n",
    "\n",
    "label_names = lbl.classes_ \n",
    "\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train,len(label_names))\n",
    "\n",
    "dims = len(feature_names)\n",
    "nb_classes = len(label_names)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(dims, 512, init='glorot_uniform'))\n",
    "model.add(PReLU((512,)))\n",
    "model.add(BatchNormalization((512,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, 512, init='glorot_uniform'))\n",
    "model.add(PReLU((512,)))\n",
    "model.add(BatchNormalization((512,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, 512, init='glorot_uniform'))\n",
    "model.add(PReLU((512,)))\n",
    "model.add(BatchNormalization((512,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, nb_classes, init='glorot_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=20, batch_size=16)\n",
    "\n",
    "def make_submission(y_pred, ids, encoder, fname):\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('id,cuisine')\n",
    "        f.write('\\n')\n",
    "        for i, y_class in zip(test_ids,lbl.inverse_transform(pred)):\n",
    "            f.write(','.join([i,y_class]))\n",
    "            f.write('\\n')\n",
    "    print(\"Wrote submission to file {}.\".format(fname))\n",
    "\n",
    "pred = model.predict_classes(X_test.toarray())\n",
    "make_submission(proba, test_ids, lbl, fname='data/keras-submit-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
